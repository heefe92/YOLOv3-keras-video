{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from yolov3 import make_seq_yolov3_model\n",
    "from utils.utils import WeightReader\n",
    "from utils.utils import preprocess_input\n",
    "from utils.utils import decode_netout\n",
    "from utils.utils import correct_yolo_boxes\n",
    "from utils.utils import do_nms\n",
    "from utils.bbox import draw_boxes\n",
    "from utils.utils import get_yolo_boxes\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense\n",
    "import time\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_h, net_w = 416, 416\n",
    "obj_thresh, nms_thresh = 0.5, 0.45\n",
    "anchors = [10, 13, 16, 30, 33, 23, 30, 61, 62, 45, 59, 119, 116, 90, 156, 198, 373, 326]\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "          \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "imgs_folder_path = 'Z:/dataset/KNU-Campus Dataset/images/20180312_181409/'\n",
    "img_name = '20180312_181409_'\n",
    "infer_model,seq_infer_model = make_seq_yolov3_model(input_shape=(416,416,3))\n",
    "\n",
    "# output_layer_weights = [infer_model.get_layer(name='conv_81').get_weights()[0],\n",
    "#                         infer_model.get_layer(name='conv_93').get_weights()[0],\n",
    "#                         infer_model.get_layer(name='conv_105').get_weights()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_accent(process_img,rows,cols,bs,class_nums,size_nums):\n",
    "    l_r = 0.0001\n",
    "    outputs=0\n",
    "    count=0\n",
    "    for i in range(len(rows)):\n",
    "        row = rows[i]\n",
    "        col = cols[i]\n",
    "        b = bs[i]\n",
    "        class_num = class_nums[i]\n",
    "        size_num = size_nums[i]\n",
    "        outputs += infer_model.output[yolo_num][:,row,col,20*b +4] + infer_model.output[size_num][:,row,col,20*b +5+ class_num]\n",
    "        count += 1\n",
    "    outputs/=count\n",
    "    start_time = time.time()\n",
    "    grads = K.gradients(outputs, infer_model.input)[0]\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "    iterate = K.function([infer_model.input], [grads])\n",
    "\n",
    "    grads_val = iterate([process_img])\n",
    "    process_img = l_r*grads_val+process_img\n",
    "    return process_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.exists('Weights/yolov3.h5')):\n",
    "    weight_reader = WeightReader('yolov3.weights')\n",
    "    weight_reader.load_weights(infer_model)\n",
    "    infer_model.save_weights('Weights/yolov3.h5')\n",
    "else :\n",
    "    infer_model.load_weights('Weights/yolov3.h5',by_name=True)\n",
    "    seq_infer_model.load_weights('Weights/yolov3.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = [[[None]*3]*13]*13\n",
    "iterates = [[[None]*3]*13]*13\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(1):\n",
    "    for j in range(1):\n",
    "        for b in range(3):\n",
    "            output = infer_model.output[0]#[:,i,j,85*b+4] + infer_model.output[2][:,i,j,85*b+5]\n",
    "            grad = K.gradients(output, infer_model.input)[0]\n",
    "            #grad /= (K.sqrt(K.mean(K.square(grad))) + 1e-5)\n",
    "            iterates[i][j][b] = K.function([infer_model.input], [grad])\n",
    "print(time.time() - start_time)\n",
    "# 3ê°œ = 70Mb, 12s\n",
    "# 425,880 Mb\n",
    "# 6 * 13*13 + 6 * 26 * 26 + 6 * 52 * 52\n",
    "\n",
    "# l_r = 0.001\n",
    "# outputs=0\n",
    "# count=0\n",
    "# for i in range(len(rows)):\n",
    "#     row = rows[i]\n",
    "#     col = cols[i]\n",
    "#     b = bs[i]\n",
    "#     class_num = class_nums[i]\n",
    "#     yolo_num = yolo_nums[i]\n",
    "#     outputs += infer_model.output[yolo_num][:,row,col,85*b +4] + infer_model.output[yolo_num][:,row,col,85*b +5+ class_num]\n",
    "#     count += 1\n",
    "# outputs/=count\n",
    "# start_time = time.time()\n",
    "# grads = K.gradients(outputs, infer_model.input)[0]\n",
    "# grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "# print(img_num)\n",
    "# print('grad time',start_time-time.time())\n",
    "# iterate = K.function([infer_model.input], [grads])\n",
    "# print('grad time',start_time-time.time())\n",
    "# grads_val = iterate([process_image])\n",
    "# print('grad time',start_time-time.time())\n",
    "# process_image = l_r * grads_val[0]+process_image\n",
    "# print('grad time',start_time-time.time())\n",
    "# yolos = seq_infer_model.predict([process_image,prev_feature[0],prev_feature[1],prev_feature[2]])\n",
    "# prev_feature=yolos[3:]\n",
    "# yolos=yolos[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(imgs_folder_path+img_name+'0002.jpg')\n",
    "image_h, image_w, _ = img.shape\n",
    "\n",
    "process_image = preprocess_input(img, net_h, net_w)\n",
    "\n",
    "\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "grad time -3.561194658279419\n",
      "grad time -3.5616955757141113\n",
      "grad time -7.479043245315552\n",
      "grad time -7.482050180435181\n",
      "2\n",
      "grad time -3.5069143772125244\n",
      "grad time -3.523475170135498\n",
      "grad time -6.921703577041626\n",
      "grad time -6.925214052200317\n",
      "3\n",
      "grad time -3.2562172412872314\n",
      "grad time -3.272758960723877\n",
      "grad time -6.775151014328003\n",
      "grad time -6.778159141540527\n",
      "4\n",
      "grad time -3.507351875305176\n",
      "grad time -3.5234227180480957\n",
      "grad time -7.067072629928589\n",
      "grad time -7.070581912994385\n",
      "5\n",
      "grad time -3.3253965377807617\n",
      "grad time -3.3414156436920166\n",
      "grad time -7.005884885787964\n",
      "grad time -7.008892774581909\n",
      "6\n",
      "grad time -3.465247392654419\n",
      "grad time -3.481292724609375\n",
      "grad time -7.29293155670166\n",
      "grad time -7.296441078186035\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2326\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2327\u001b[1;33m           \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2328\u001b[0m           \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Operation 'zero_padding2d_7/Pad' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m       \u001b[0mxla_compile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaCompile\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2330\u001b[0m         \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2331\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2332\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Operation 'zero_padding2d_7/Pad' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1b7a8b3abbc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m/=\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(loss, variables)\u001b[0m\n\u001b[0;32m   2701\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m     \"\"\"\n\u001b[1;32m-> 2703\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[0;32m    492\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[1;32m--> 494\u001b[1;33m                             gate_gradients, aggregation_method, stop_gradients)\n\u001b[0m\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[0;32m    634\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 636\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    637\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    383\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaScope\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    634\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 636\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    637\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_PadGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    602\u001b[0m                                array_ops.stack([array_ops.rank(x), 1]))\n\u001b[0;32m    603\u001b[0m   \u001b[1;31m# Make it a 1-D tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m   \u001b[0mbegin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_before\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m   \u001b[0msizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m   \u001b[0mx_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   7321\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7322\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 7323\u001b[1;33m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[0;32m   7324\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7325\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3403\u001b[0m       self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[1;32m-> 3404\u001b[1;33m                              compute_device=compute_device)\n\u001b[0m\u001b[0;32m   3405\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[1;34m(self, op, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3459\u001b[0m     \u001b[1;31m# Apply a kernel label if one has been specified for this op type.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3461\u001b[1;33m       \u001b[0mkernel_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op_to_kernel_label_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3462\u001b[0m       op._set_attr(\"_kernel\",  # pylint: disable=protected-access\n\u001b[0;32m   3463\u001b[0m                    attr_value_pb2.AttrValue(s=compat.as_bytes(kernel_label)))\n",
      "\u001b[1;32mF:\\Users\\heecheol\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mtype\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2220\u001b[0m     \u001b[1;34m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2221\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2222\u001b[1;33m       \u001b[0mop_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationOpType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2223\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mop_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2224\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prev_feature=[]\n",
    "for img_num in range(1000):\n",
    "    img_num2str=str(img_num)\n",
    "    while(len(img_num2str)<4):\n",
    "        img_num2str='0'+img_num2str\n",
    "\n",
    "    img = cv2.imread(imgs_folder_path+img_name+img_num2str+'.jpg')\n",
    "    image_h, image_w, _ = img.shape\n",
    "    \n",
    "    process_image = preprocess_input(img, net_h, net_w)\n",
    "    if img_num == 0:\n",
    "        yolos = infer_model.predict(process_image)\n",
    "        prev_feature=yolos[3:]\n",
    "        yolos=yolos[:3]\n",
    "    else:\n",
    "        yolos = infer_model.predict(process_image)\n",
    "        prev_feature=yolos[3:]\n",
    "        yolos=yolos[:3]\n",
    "        l_r = 0.001\n",
    "        outputs=0\n",
    "        count=0\n",
    "        for i in range(len(rows)):\n",
    "            row = rows[i]\n",
    "            col = cols[i]\n",
    "            b = bs[i]\n",
    "            class_num = class_nums[i]\n",
    "            yolo_num = yolo_nums[i]\n",
    "            outputs += infer_model.output[yolo_num][:,row,col,85*b +4] + infer_model.output[yolo_num][:,row,col,85*b +5+ class_num]\n",
    "            count += 1\n",
    "        outputs/=count\n",
    "        start_time = time.time()\n",
    "        grads = K.gradients(outputs, infer_model.input)[0]\n",
    "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "        print(img_num)\n",
    "        print('grad time',start_time-time.time())\n",
    "        iterate = K.function([infer_model.input], [grads])\n",
    "        print('grad time',start_time-time.time())\n",
    "        grads_val = iterate([process_image])\n",
    "        print('grad time',start_time-time.time())\n",
    "        process_image = l_r * grads_val[0]+process_image\n",
    "        print('grad time',start_time-time.time())\n",
    "        yolos = seq_infer_model.predict([process_image,prev_feature[0],prev_feature[1],prev_feature[2]])\n",
    "        prev_feature=yolos[3:]\n",
    "        yolos=yolos[:3]\n",
    "        \n",
    "        \n",
    "    \n",
    "    #yolos = infer_model.predict(process_image)\n",
    "    boxes = []\n",
    "\n",
    "    for i in range(len(yolos)):\n",
    "        # decode the output of the network\n",
    "        yolo_anchors = anchors[(2 - i) * 6:(3 - i) * 6]\n",
    "        boxes += decode_netout(yolos[i][0], yolo_anchors, obj_thresh, net_h, net_w, i)\n",
    "    #print(boxes)\n",
    "    # correct the sizes of the bounding boxes\n",
    "    correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
    "\n",
    "    # suppress non-maximal boxes\n",
    "    do_nms(boxes, nms_thresh)\n",
    "\n",
    "    # draw bounding boxes on the image using labels\n",
    "    rows,cols,bs,class_nums,yolo_nums = draw_boxes(img, boxes, labels, obj_thresh, debug = False)\n",
    "    #cv2.imwrite('outputs/detect/'+img_name+img_num2str+'_detected.jpg',cv2.resize(img,(1280,720)))\n",
    "    cv2.imshow('video with bboxes', cv2.resize(img,(1280,720)))\n",
    "    cv2.waitKey(6)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model.output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Z:/dataset/KNU-Campus Dataset/videos/scene11.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "while(True):\n",
    "    count2str = str(count)\n",
    "    \n",
    "    while(len(count2str)<4):\n",
    "        count2str='0'+count2str\n",
    "    ret,frame = cap.read()\n",
    "    if (ret):\n",
    "        cv2.imwrite(imgs_folder_path+img_name+count2str+'.jpg',frame)\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
