{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov3 import make_seq_yolov3_model\n",
    "from utils.utils import WeightReader\n",
    "from utils.utils import preprocess_input\n",
    "from utils.utils import decode_netout\n",
    "from utils.utils import correct_yolo_boxes\n",
    "from utils.utils import do_nms\n",
    "from utils.bbox import draw_boxes\n",
    "from utils.utils import get_yolo_boxes\n",
    "\n",
    "import time\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_h, net_w = 416, 416\n",
    "obj_thresh, nms_thresh = 0.5, 0.45\n",
    "anchors = [10, 13, 16, 30, 33, 23, 30, 61, 62, 45, 59, 119, 116, 90, 156, 198, 373, 326]\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "          \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "imgs_folder_path = 'Z:/dataset/KNU-Campus Dataset/images/20180312_172240/'\n",
    "img_name = '20180312_172240_'\n",
    "infer_model,seq_infer_model = make_seq_yolov3_model(input_shape=(416,416,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_accent(process_img,rows,cols,bs,class_nums,size_nums):\n",
    "    l_r = 0.0001\n",
    "    outputs=0\n",
    "    count=0\n",
    "    for i in range(len(rows)):\n",
    "        row = rows[i]\n",
    "        col = cols[i]\n",
    "        b = bs[i]\n",
    "        class_num = class_nums[i]\n",
    "        size_num = size_nums[i]\n",
    "        outputs += infer_model.output[yolo_num][:,row,col,20*b +4] + infer_model.output[size_num][:,row,col,20*b +5+ class_num]\n",
    "        count += 1\n",
    "    outputs/=count\n",
    "    start_time = time.time()\n",
    "    grads = K.gradients(outputs, infer_model.input)[0]\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "    iterate = K.function([infer_model.input], [grads])\n",
    "\n",
    "    grads_val = iterate([process_img])\n",
    "    process_img = l_r*grads_val+process_img\n",
    "    return process_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.exists('Weights/yolov3.h5')):\n",
    "    weight_reader = WeightReader('yolov3.weights')\n",
    "    weight_reader.load_weights(infer_model)\n",
    "    infer_model.save_weights('Weights/yolov3.h5')\n",
    "else :\n",
    "    infer_model.load_weights('Weights/yolov3.h5',by_name=True)\n",
    "    seq_infer_model.load_weights('Weights/yolov3.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.039347171783447\n"
     ]
    }
   ],
   "source": [
    "grads = [[[None]*3]*13]*13\n",
    "iterates = [[[None]*3]*13]*13\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(1):\n",
    "    for j in range(1):\n",
    "        for b in range(3):\n",
    "            output = infer_model.output[0]#[:,i,j,85*b+4] + infer_model.output[2][:,i,j,85*b+5]\n",
    "            grad = K.gradients(output, infer_model.input)[0]\n",
    "            #grad /= (K.sqrt(K.mean(K.square(grad))) + 1e-5)\n",
    "            iterates[i][j][b] = K.function([infer_model.input], [grad])\n",
    "print(time.time() - start_time)\n",
    "# 3ê°œ = 70Mb, 12s\n",
    "# 425,880 Mb\n",
    "# 6 * 13*13 + 6 * 26 * 26 + 6 * 52 * 52\n",
    "\n",
    "# l_r = 0.001\n",
    "# outputs=0\n",
    "# count=0\n",
    "# for i in range(len(rows)):\n",
    "#     row = rows[i]\n",
    "#     col = cols[i]\n",
    "#     b = bs[i]\n",
    "#     class_num = class_nums[i]\n",
    "#     yolo_num = yolo_nums[i]\n",
    "#     outputs += infer_model.output[yolo_num][:,row,col,85*b +4] + infer_model.output[yolo_num][:,row,col,85*b +5+ class_num]\n",
    "#     count += 1\n",
    "# outputs/=count\n",
    "# start_time = time.time()\n",
    "# grads = K.gradients(outputs, infer_model.input)[0]\n",
    "# grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "# print(img_num)\n",
    "# print('grad time',start_time-time.time())\n",
    "# iterate = K.function([infer_model.input], [grads])\n",
    "# print('grad time',start_time-time.time())\n",
    "# grads_val = iterate([process_image])\n",
    "# print('grad time',start_time-time.time())\n",
    "# process_image = l_r * grads_val[0]+process_image\n",
    "# print('grad time',start_time-time.time())\n",
    "# yolos = seq_infer_model.predict([process_image,prev_feature[0],prev_feature[1],prev_feature[2]])\n",
    "# prev_feature=yolos[3:]\n",
    "# yolos=yolos[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'gradients_41/conv_0/convolution_grad/Conv2DBackpropInput:0' shape=(?, 416, 416, 3) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(iterates[0][0][1].outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13747549057006836\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(imgs_folder_path+img_name+'0002.jpg')\n",
    "image_h, image_w, _ = img.shape\n",
    "\n",
    "process_image = preprocess_input(img, net_h, net_w)\n",
    "start_time = time.time()\n",
    "grads_val = iterates[0][0][0]([process_image])\n",
    "\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prev_feature=[]\n",
    "for img_num in range(1000):\n",
    "    img_num2str=str(img_num)\n",
    "    while(len(img_num2str)<4):\n",
    "        img_num2str='0'+img_num2str\n",
    "\n",
    "    img = cv2.imread(imgs_folder_path+img_name+img_num2str+'.jpg')\n",
    "    image_h, image_w, _ = img.shape\n",
    "    \n",
    "    process_image = preprocess_input(img, net_h, net_w)\n",
    "    if img_num == 0:\n",
    "        yolos = infer_model.predict(process_image)\n",
    "        prev_feature=yolos[3:]\n",
    "        yolos=yolos[:3]\n",
    "    else:\n",
    "        yolos = infer_model.predict(process_image)\n",
    "        prev_feature=yolos[3:]\n",
    "        yolos=yolos[:3]\n",
    "        l_r = 0.001\n",
    "        outputs=0\n",
    "        count=0\n",
    "        for i in range(len(rows)):\n",
    "            row = rows[i]\n",
    "            col = cols[i]\n",
    "            b = bs[i]\n",
    "            class_num = class_nums[i]\n",
    "            yolo_num = yolo_nums[i]\n",
    "            outputs += infer_model.output[yolo_num][:,row,col,85*b +4] + infer_model.output[yolo_num][:,row,col,85*b +5+ class_num]\n",
    "            count += 1\n",
    "        outputs/=count\n",
    "        start_time = time.time()\n",
    "        grads = K.gradients(outputs, infer_model.input)[0]\n",
    "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "        print(img_num)\n",
    "        print('grad time',start_time-time.time())\n",
    "        iterate = K.function([infer_model.input], [grads])\n",
    "        print('grad time',start_time-time.time())\n",
    "        grads_val = iterate([process_image])\n",
    "        print('grad time',start_time-time.time())\n",
    "        process_image = l_r * grads_val[0]+process_image\n",
    "        print('grad time',start_time-time.time())\n",
    "        yolos = seq_infer_model.predict([process_image,prev_feature[0],prev_feature[1],prev_feature[2]])\n",
    "        prev_feature=yolos[3:]\n",
    "        yolos=yolos[:3]\n",
    "        \n",
    "        \n",
    "    \n",
    "    #yolos = infer_model.predict(process_image)\n",
    "    boxes = []\n",
    "\n",
    "    for i in range(len(yolos)):\n",
    "        # decode the output of the network\n",
    "        yolo_anchors = anchors[(2 - i) * 6:(3 - i) * 6]\n",
    "        boxes += decode_netout(yolos[i][0], yolo_anchors, obj_thresh, net_h, net_w, i)\n",
    "    #print(boxes)\n",
    "    # correct the sizes of the bounding boxes\n",
    "    correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
    "\n",
    "    # suppress non-maximal boxes\n",
    "    do_nms(boxes, nms_thresh)\n",
    "\n",
    "    # draw bounding boxes on the image using labels\n",
    "    rows,cols,bs,class_nums,yolo_nums = draw_boxes(img, boxes, labels, obj_thresh, debug = False)\n",
    "    cv2.imwrite('outputs/detect/'+img_name+img_num2str+'_detected.jpg',cv2.resize(img,(1280,720)))\n",
    "    cv2.imshow('video with bboxes', cv2.resize(img,(1280,720)))\n",
    "    cv2.waitKey(6)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model.output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Z:/dataset/KNU-Campus Dataset/videos/scene11.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "while(True):\n",
    "    count2str = str(count)\n",
    "    \n",
    "    while(len(count2str)<4):\n",
    "        count2str='0'+count2str\n",
    "    ret,frame = cap.read()\n",
    "    if (ret):\n",
    "        cv2.imwrite(imgs_folder_path+img_name+count2str+'.jpg',frame)\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
